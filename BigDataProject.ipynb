{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: requests>=2.11.1 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /opt/conda/lib/python3.6/site-packages (from tweepy)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.11.1->tweepy)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: textblob in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.6/site-packages (from textblob)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk>=3.1->textblob)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-0.9.6.tar.gz (67kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.0MB/s ta 0:00:011\n",
      "\u001b[?25hBuilding wheels for collected packages: jsonpickle\n",
      "  Running setup.py bdist_wheel for jsonpickle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/c8/c5/88/0975a9ef0ae87799d3a4ae54244ca8f76eaaf03395f48a5129\n",
      "Successfully built jsonpickle\n",
      "Installing collected packages: jsonpickle\n",
      "Successfully installed jsonpickle-0.9.6\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 9.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "[nltk_data] Downloading package brown to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "!pip install textblob\n",
    "!pip install jsonpickle\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from textblob import TextBlob\n",
    "import unicodedata\n",
    " \n",
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console\n",
    "        consumer_key = 'sUHh7JRlyO8FyR13IDeA8fU9i'\n",
    "        consumer_secret = 'eop24iZFggjofseChtXMeE9rzqrcYAI7ygAj2WhXDNRhL2yCNF'\n",
    "        access_token = '841161497254420480-mJgm5iUzsZYbj4GOALwrAUJU6pKjA4l'\n",
    "        access_token_secret = '0HcN005SPyZ8iXnCdzPVTPn2EEYsU2MjbffEiDEiExIPg'\n",
    "        self.lang = 'en'\n",
    "        self.sinceId = None\n",
    "        self.max_id = -1L\n",
    " \n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "            #self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            self.auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            #self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "            \n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    " \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    " \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        return 'neutral' #Stub Method for now\n",
    "        '''\n",
    "        create TextBlob object of passed tweet text\n",
    "        analysis = TextBlob(self.clean_tweet(tweet))\n",
    "        set sentiment\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0:\n",
    "            return 'neutral'\n",
    "        else:\n",
    "            return 'negative'\n",
    "        '''\n",
    "        \n",
    "    def isEnglish(self,s):\n",
    "        '''\n",
    "        Consider only the tweets that have english alphabets in them\n",
    "        '''\n",
    "        try:\n",
    "            s.encode(encoding='utf-8').decode('ascii')\n",
    "        except UnicodeDecodeError:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    " \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        \n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    " \n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q = query, count = count )# , lang = self.lang )\n",
    " \n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                 #Check if the tweet corresponds to english language\n",
    "                 #if ( self.isEnglish(tweet.text) == False ):\n",
    "                        #continue\n",
    "    \n",
    "                 parsed_tweet = {}\n",
    " \n",
    "                 # saving text of tweet\n",
    "                 parsed_tweet['text'] =  tweet.text \n",
    "                 # saving sentiment of tweet\n",
    "                 parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    " \n",
    "                 # appending parsed tweet to tweets list\n",
    "                 if tweet.retweet_count > 0:\n",
    "                     # if tweet has retweets, ensure that it is appended only once\n",
    "                     if parsed_tweet not in tweets:\n",
    "                         tweets.append(parsed_tweet)\n",
    "                 else:\n",
    "                     tweets.append(parsed_tweet)\n",
    " \n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    " \n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # creating object of TwitterClient Class\n",
    "    api = TwitterClient()\n",
    "    # calling function to get tweets\n",
    "    tweets = api.get_tweets(query = 'airlines', count = 2000)\n",
    "    print ( len(tweets))\n",
    "    #for tweet in tweets:\n",
    "    #   print(tweet)\n",
    " \n",
    "    # picking positive tweets from tweets\n",
    "#     ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive']\n",
    "#     # percentage of positive tweets\n",
    "#     print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets)))\n",
    "#     # picking negative tweets from tweets\n",
    "#     ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative']\n",
    "#     # percentage of negative tweets\n",
    "#     print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets)))\n",
    "#     # percentage of neutral tweets\n",
    "#     print(\"Neutral tweets percentage: {} % \\\n",
    "#         \".format(100*len(tweets - ntweets - ptweets)/len(tweets)))\n",
    " \n",
    "#     # printing first 5 positive tweets\n",
    "#     print(\"\\n\\nPositive tweets:\")\n",
    "#     for tweet in ptweets[:10]:\n",
    "#         print(tweet['text'])\n",
    " \n",
    "#     # printing first 5 negative tweets\n",
    "#     print(\"\\n\\nNegative tweets:\")\n",
    "#     for tweet in ntweets[:10]:\n",
    "#         print(tweet['text'])\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    # calling main function\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keywords:\n",
    "    def __init__(self):\n",
    "        self.keywords = ['Alaska Airlines','Allegiant Airlines','American Airlines','Delta Airlines','Frontier Airlines','Hawaiian Airlines','JetBlue','SouthWest Airlines','Spirit Airlines','Sun Country Airlines','United Airlines','Virgin America']\n",
    "        \n",
    "    def getKeyWords():\n",
    "        return self.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000 tweets\n",
      "Downloaded 100 tweets\n",
      "Downloaded 200 tweets\n",
      "Downloaded 300 tweets\n",
      "Downloaded 400 tweets\n",
      "Downloaded 500 tweets\n",
      "Downloaded 600 tweets\n",
      "Downloaded 699 tweets\n",
      "Downloaded 797 tweets\n",
      "Downloaded 897 tweets\n",
      "Downloaded 997 tweets\n",
      "Downloaded 1097 tweets\n",
      "Downloaded 1197 tweets\n",
      "Downloaded 1297 tweets\n",
      "Downloaded 1397 tweets\n",
      "Downloaded 1497 tweets\n",
      "Downloaded 1597 tweets\n",
      "Downloaded 1697 tweets\n",
      "Downloaded 1797 tweets\n",
      "Downloaded 1897 tweets\n",
      "Downloaded 1997 tweets\n",
      "Downloaded 2097 tweets\n",
      "Downloaded 2197 tweets\n",
      "Downloaded 2297 tweets\n",
      "Downloaded 2397 tweets\n",
      "Downloaded 2494 tweets\n",
      "Downloaded 2594 tweets\n",
      "Downloaded 2690 tweets\n",
      "Downloaded 2788 tweets\n",
      "Downloaded 2888 tweets\n",
      "Downloaded 2988 tweets\n",
      "Downloaded 3088 tweets\n",
      "Downloaded 3186 tweets\n",
      "Downloaded 3286 tweets\n",
      "Downloaded 3386 tweets\n",
      "Downloaded 3486 tweets\n",
      "Downloaded 3586 tweets\n",
      "Downloaded 3686 tweets\n",
      "Downloaded 3786 tweets\n",
      "Downloaded 3886 tweets\n",
      "Downloaded 3986 tweets\n",
      "Downloaded 4086 tweets\n",
      "Downloaded 4186 tweets\n",
      "Downloaded 4285 tweets\n",
      "Downloaded 4385 tweets\n",
      "Downloaded 4485 tweets\n",
      "Downloaded 4585 tweets\n",
      "Downloaded 4685 tweets\n",
      "Downloaded 4785 tweets\n",
      "Downloaded 4882 tweets\n",
      "Downloaded 4980 tweets\n",
      "Downloaded 5075 tweets\n",
      "Downloaded 5161 tweets\n",
      "Downloaded 5246 tweets\n",
      "Downloaded 5338 tweets\n",
      "Downloaded 5420 tweets\n",
      "Downloaded 5504 tweets\n",
      "Downloaded 5594 tweets\n",
      "Downloaded 5682 tweets\n",
      "Downloaded 5782 tweets\n",
      "Downloaded 5877 tweets\n",
      "Downloaded 5976 tweets\n",
      "Downloaded 6071 tweets\n",
      "Downloaded 6165 tweets\n",
      "Downloaded 6254 tweets\n",
      "Downloaded 6351 tweets\n",
      "Downloaded 6447 tweets\n",
      "Downloaded 6543 tweets\n",
      "Downloaded 6643 tweets\n",
      "Downloaded 6743 tweets\n",
      "Downloaded 6829 tweets\n",
      "Downloaded 6929 tweets\n",
      "Downloaded 7022 tweets\n",
      "Downloaded 7116 tweets\n",
      "Downloaded 7212 tweets\n",
      "Downloaded 7312 tweets\n",
      "Downloaded 7412 tweets\n",
      "Downloaded 7512 tweets\n",
      "Downloaded 7611 tweets\n",
      "Downloaded 7711 tweets\n",
      "Downloaded 7807 tweets\n",
      "Downloaded 7903 tweets\n",
      "Downloaded 8001 tweets\n",
      "Downloaded 8094 tweets\n",
      "Downloaded 8192 tweets\n",
      "Downloaded 8286 tweets\n",
      "Downloaded 8386 tweets\n",
      "Downloaded 8486 tweets\n",
      "Downloaded 8582 tweets\n",
      "Downloaded 8672 tweets\n",
      "Downloaded 8769 tweets\n",
      "Downloaded 8866 tweets\n",
      "Downloaded 8954 tweets\n",
      "Downloaded 9054 tweets\n",
      "Downloaded 9144 tweets\n",
      "Downloaded 9234 tweets\n",
      "Downloaded 9321 tweets\n",
      "Downloaded 9420 tweets\n",
      "Downloaded 9518 tweets\n",
      "Downloaded 9618 tweets\n",
      "Downloaded 9714 tweets\n",
      "Downloaded 9811 tweets\n",
      "Downloaded 9911 tweets\n",
      "Downloaded 10011 tweets\n",
      "Downloaded 10011 tweets, Saved to tweets.txt\n"
     ]
    }
   ],
   "source": [
    "#Fetch The Tweets\n",
    "# Replace the API_KEY and API_SECRET with your application's key and secret.\n",
    "import jsonpickle\n",
    "consumer_key = 'sUHh7JRlyO8FyR13IDeA8fU9i'\n",
    "consumer_secret = 'eop24iZFggjofseChtXMeE9rzqrcYAI7ygAj2WhXDNRhL2yCNF'\n",
    "access_token = '841161497254420480-mJgm5iUzsZYbj4GOALwrAUJU6pKjA4l'\n",
    "\n",
    "access_token_secret = '0HcN005SPyZ8iXnCdzPVTPn2EEYsU2MjbffEiDEiExIPg'\n",
    "auth = tweepy.AppAuthHandler(consumer_key,consumer_secret )\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)\n",
    "    \n",
    "searchQuery = 'airlines'  # this is what we're searching for\n",
    "maxTweets = 10000 # Some arbitrary large number\n",
    "tweetsPerQry = 100  # this is the max the API permits\n",
    "fName = 'tweets.txt' # We'll store the tweets in a text file.\n",
    "\n",
    "\n",
    "# If results from a specific ID onwards are reqd, set since_id to that ID.\n",
    "# else default to no lower limit, go as far back as API allows\n",
    "sinceId = None\n",
    "\n",
    "# If results only below a specific ID are, set max_id to that ID.\n",
    "# else default to no upper limit, start from the most recent tweet matching the search query.\n",
    "max_id = -1\n",
    "\n",
    "tweetCount = 0\n",
    "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "\n",
    "with open(fName, 'w') as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry)\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceId)\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                f.write(jsonpickle.encode(tweet._json, unpicklable=False) +\n",
    "                        '\\n')\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Laelling for Each Tweet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
